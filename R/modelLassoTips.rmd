---
title: "Final Project"
subtitle: "Data Exploration"
author: ""
date: "2019-Feb-25"
fontsize: 8 pt
output:
  #    beamer_presentation: #everything after hash "#" will be ignored 
pdf_document:
number_sections: false
fig_width: 6
fig_height: 4
---
  
  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      #include = TRUE, 
                      eval = TRUE, 
                      
                      fig.width = 6, fig.height = 4,
                      results='hold',
                      warning = FALSE,
                      message=FALSE,
                      cache = TRUE,
                      digits = 3) 
```

```{r,echo=FALSE,results='hide', message=FALSE}
# Packages and Data Parser
#Note: Be sure plyr is loaded before dplyr
PackageList =c("plyr","dplyr","tidyverse","lubridate","censusapi","forcats","rpart","rpart.plot","tictoc","gbm","rattle","stringr","glmnet")
NewPackages=PackageList[!(PackageList %in% 
                            installed.packages()[,"Package"])]
if(length(NewPackages)) install.packages(NewPackages,repos = "http://cran.us.r-project.org")
lapply(PackageList,require,character.only=TRUE)#array function

options(tibble.print_max = Inf, tibble.print_min = 20) 
set.seed(1) #Always set the seed for reproducibility
```

Load data and begin generating exploratory plots.

```{r,"Load Data"}
source("taxiData.R")
#Load records from taxi data source and store as a dataframe
data1m <- taxiData(2000000)
df <- data.frame(data1m$rawData)
rm(data1m) #Drop old data
gc()
df$dropoff_community_area<-as.factor(df$dropoff_community_area)
df$dropoff_centroid_location.coordinates<-as.character(df$dropoff_centroid_location.coordinates)
df$pickup_centroid_location.coordinates<-as.character(df$pickup_centroid_location.coordinates)
df$trip_total<-as.numeric(df$trip_total)
df$extras<-as.numeric(df$extras)
df$tolls<-as.numeric(df$tolls)
#Load census data by Chicago Community Area
ccaData <- read.csv("ChicagoCCAData.csv")
ccaData$CCA.Code<-as.factor(ccaData$CCA.Code)
ccaData$GEOG<-as.factor(ccaData$GEOG)
#Look up name of pickup CCA and add to df
df<- df %>% left_join(dplyr::select(ccaData,GEOG,CCA.Code),by=c("pickup_community_area"="CCA.Code"))
names(df)[names(df) == 'GEOG'] <- 'pickup_area'
#Look up name of dropoff CCA and add to df
df<- df %>% left_join(dplyr::select(ccaData,GEOG,CCA.Code),by=c("dropoff_community_area"="CCA.Code"))
names(df)[names(df) == 'GEOG'] <- 'dropoff_area'
#Look up population>16yo of pickup CCA and add to df
df<- df %>% left_join(dplyr::select(ccaData,POP_16OV,CCA.Code),by=c("pickup_community_area"="CCA.Code"))
names(df)[names(df) == 'POP_16OV'] <- 'Pop16Plus'
#Look up Labor Force of pickup CCA and add to df
df<- df %>% left_join(dplyr::select(ccaData,IN_LBFRC,CCA.Code),by=c("pickup_community_area"="CCA.Code"))
names(df)[names(df) == 'IN_LBFRC'] <- 'IN_LBFRC'
#Look up Unemp of pickup CCA and add to df
df<- df %>% left_join(dplyr::select(ccaData,UNEMP,CCA.Code),by=c("pickup_community_area"="CCA.Code"))
names(df)[names(df) == 'UNEMP'] <- 'UNEMP'
#Look up Unemp of pickup CCA and add to df
df<- df %>% left_join(dplyr::select(ccaData,MEDINC,CCA.Code),by=c("pickup_community_area"="CCA.Code"))
names(df)[names(df) == 'MEDINC'] <- 'MedIncome'
```
Clean data. For instance, "Chicago Elite Cab Corp. (Chicago Carriag" and "Chicago Elite Cab Corp." are clearly the same firm. We replace the former with the latter. 
We add factors for the Start Date (as opposed to date time), End Date, and Start Day of Week.
* In company, set "Chicago Elite Cab Corp. (Chicago Carriag" equal to "Chicago Elite Cab Corp."
* Add factor for Start Date (not date time)
* Add factor for End Date (not date time)
* Add factor for End Day of week
* Add factor for End month
* Add factor for End hour

```{r, "Add columns"}
df$company[df$company=="Chicago Elite Cab Corp. (Chicago Carriag"] <- "Chicago Elite Cab Corp."
df$startDate <- date(df$trip_start_timestamp)
df$endDate <- date(df$trip_end_timestamp)
df$endDay <- wday(df$trip_end_timestamp,label=TRUE)
df$endDay <- factor(df$endDay,ordered=FALSE)
df$endMonth <- month(df$trip_end_timestamp,label=TRUE)
df$endMonth <- factor(df$endMonth,ordered=FALSE)
df$endHour <- hour(str_replace(df$trip_end_timestamp,"T"," "))
df$endHour <- factor(df$endHour,ordered=FALSE)
#Replace <NA> with string "NA" which can be used for grouping
df$company <- fct_explicit_na(df$company,"NA") 
df$LaborPart <- ((df$IN_LBFRC-df$UNEMP)/df$IN_LBFRC)
```

Throw out all rows where NAs exist for dropoff/pickup location and other fields to be used in model. We will group all pickup areas originating fewer than 0.5% of all trip into 1 factor called "Other"

```{r, "Create slim dataset for modeling"}
#Calculate # trips by area and order, most to least. Pick out those with at least 0.5% of trips. 
topPickup <- df %>% drop_na(c("pickup_area")) %>% dplyr::group_by(pickup_area) %>% tally(sort=TRUE)
topPickup05Perc <- topPickup[topPickup$n>(.002*nrow(drop_na(df,c("pickup_area")))),]
#Remove unused levels
topPickup05Perc$pickup_area <- droplevels(topPickup05Perc$pickup_area)
#Add levels, including one for "Other"
df$pickup_area_group <- as.factor(ifelse(!df$pickup_area %in% topPickup05Perc$pickup_area,"Other",df$pickup_area))
levels(df$pickup_area_group)<-c(levels(topPickup05Perc$pickup_area),"Other")

#Do the same thing for company to reduce the number of factor levels
topCompany <- df %>% drop_na(c("company")) %>% dplyr::group_by(company) %>% tally(sort=TRUE)
topCompany05Perc <- topCompany[topCompany$n>(.005*nrow(drop_na(df,c("company")))),]

topCompany05Perc$company <- droplevels(topCompany05Perc$company)
#Add levels, including one for "Other"
df$company_group <- as.factor(ifelse(!df$company %in% topCompany05Perc$company,"Other",df$company))
levels(df$company_group)<-c(levels(topCompany05Perc$company),"Other")

#Filter on the following columns--drop all rows where NA encountered in any column
colFilter <- c("company_group","payment_type","tips","trip_miles","trip_seconds","endDay","endMonth","endHour","pickup_area_group","fare","MedIncome","LaborPart")
dfSlim <- df[colFilter] %>% drop_na()
#Drop records where fare is below the min, likely bad
dfSlim <- dfSlim[dfSlim$fare>0,]
#Drop fare since obviously large fares will drive large tips
#dfSlim <- dfSlim[,-which(names(dfSlim) %in% c("fare"))]
cat("Filtering NA records left ", round(100*nrow(dfSlim)/nrow(df),1),"% of data. Dropping original dataframe. Leaves ", nrow(dfSlim)," total records.")
#rm(df)
#gc()
```

```{r}
#Drop any row containing NA in any column
dfTree <- dfSlim
dfTree <- dfTree[complete.cases(dfTree),]

nSample <- floor(0.75*nrow(dfTree))
train_ind <- sample(seq_len(nrow(dfTree)), size = nSample)

trainSample <- dfTree[train_ind,] #drop the final redundant dummy var for target_control
validateSample <- dfTree[-train_ind,]
```
# Lassos

We will test the lasso (alpha=1) and elastic net (alpha=0.5). When using lambda.1se, the lasso's L1 penalty leaves on 6 factors while lambda.min returns many more (>50)

```{r, "Lasso Tips"}
library(dplyr)

vars_name <- trainSample[,-which(names(trainSample) %in% c("tips"))] %>% 
  select_if(function(col) is.factor(col) | is.numeric(col)) %>% 
  colnames() %>% 
  str_c(collapse = "+") 
model_string <- paste("tips  ~",vars_name )

x_train <- model.matrix(as.formula(model_string), trainSample)

lasso_cv <- cv.glmnet(x=x_train,y = as.matrix(trainSample$tips), family = "gaussian", alpha=0, standardize=TRUE, nfolds=10)
plot(lasso_cv)
lasso <- glmnet(x=x_train,y = as.matrix(trainSample$tips), family = "gaussian", alpha=0, standardize=TRUE,intercept = TRUE)


c<-coef(lasso_cv,s='lambda.1se',exact=TRUE)
inds<-which(c!=0)
variables<-row.names(c)[inds]
betas<-c[inds]
cbind(variables,round(betas,6))

plot(lasso)
plot(lasso, xvar = "lambda", label = TRUE)

```
```{r, "Elastic Net Tips"}
library(dplyr)

vars_name <- trainSample[,-which(names(trainSample) %in% c("tips"))] %>% 
  select_if(function(col) is.factor(col) | is.numeric(col)) %>% 
  colnames() %>% 
  str_c(collapse = "+") 
model_string <- paste("tips  ~",vars_name )

x_train <- model.matrix(as.formula(model_string), trainSample)

lasso_cv <- cv.glmnet(x=x_train,y = as.matrix(trainSample$tips), family = "gaussian", alpha=0, standardize=TRUE, nfolds=10)
plot(lasso_cv)
lasso <- glmnet(x=x_train,y = as.matrix(trainSample$tips), family = "gaussian", alpha=0, standardize=TRUE,intercept = TRUE)

a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
  cv <- cv.glmnet(x=x_train,y = as.matrix(trainSample$tips), family = "gaussian", standardize=TRUE,intercept = TRUE, alpha = i)
  data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(x=x_train,y = as.matrix(trainSample$tips), family = "gaussian", standardize=TRUE,intercept = TRUE, lambda = cv3$lambda.1se, alpha = cv3$alpha)
c<-coef(md3)

inds<-which(c!=0)
variables<-row.names(c)[inds]
betas<-c[inds]
cbind(variables,round(betas,6))

plot(md3)
plot(md3, xvar = "lambda", label = TRUE)

```


